# MySQL
`高性能mysql`
`DDIA`
`mysql技术内幕`

## Questions

~~~
    explain结果中的type字段。你的查询中分别是：
    1.type: index 
    解释：index：这种类型表示是mysql会对整个该索引进行扫描。要想用到这种类型的索引，对这个索引并无特别要求，只要是索引，或者某个复合索引的一部分，mysql都可能会采用index类型的方式扫描。但是呢，缺点是效率不高，mysql会从索引中的第一个数据一个个的查找到最后一个数据，直到找到符合判断条件的某个索引。

    2.type: ref
    ref：这种类型表示mysql会根据特定的算法快速查找到某个符合条件的索引，而不是会对索引中每一个数据都进行一一的扫描判断，也就是所谓你平常理解的使用索引查询会更快的取出数据。而要想实现这种查找，索引却是有要求的，要实现这种能快速查找的算法，索引就要满足特定的数据结构。简单说，也就是索引字段的数据必须是有序的，才能实现这种类型的查找，才能利用到索引。
~~~

#### **1. MySQL锁有几种；死锁是怎么产生的**
`To be Finished`

- 1 两种类型的锁:

~~~
    (1)共享锁(读锁) 
        读锁共享，多个客户在同一时刻可以同时读取资源,而互不干扰；
    (2)排他锁(写锁)
        写锁排他，一个写锁会阻塞其他的写锁和读锁；
    
    锁粒度(两种最重要的锁策略)
    (1)表锁
        最基本的锁策略, 开销小
    (2)行级锁
        行级锁只在存储引擎层实现，
~~~

- 2 死锁：指两个或者多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致的恶性循环的现象， 为了解决这种问题，数据库系统实现了各种死锁检测和死锁超时机制，当死锁发生时，只有部分或者完全回滚其中的一个事务，才能打破死锁；

- 3 乐观锁，悲观锁（哎， 当初太年轻， 这两个technic speaking， 不算是锁， 两种并发控制策略见题9， 10）

~~~
    (1) 乐观锁
    乐观并发控制（又名“乐观锁”，Optimistic Concurrency Control，缩写“OCC”）是一种并发控制的方法。它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，正在提交的事务会进行回滚。

    读取：事务将数据读入缓存，这时系统会给事务分派一个时间戳。

    校验：事务执行完毕后，进行提交。这时同步校验所有事务，如果事务所读取的数据在读取之后又被其他事务修改，则产生冲突，事务被中断回滚。

    写入：通过校验阶段后，将更新的数据写入数据库。

    乐观并发控制多数用于数据争用不大、冲突较少的环境中（读多写少的应用场景），这种环境中，偶尔回滚事务的成本会低于读取数据时锁定数据的成本，因此可以获得比其他并发控制方法更高的吞吐量。

    乐观锁一般来说有以下2种方式：

    A. 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。

    B. 使用时间戳（timestamp）。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。

    (2)悲观锁
    悲观并发控制（又名“悲观锁”，Pessimistic Concurrency Control，缩写“PCC”）是一种并发控制的方法。它可以阻止一个事务以影响其他用户的方式来修改数据。如果一个事务执行的操作读某行数据应用了锁，那只有当这个事务把锁释放，其他事务才能够执行与该锁冲突的操作。

    悲观并发控制主要用于数据争用激烈的环境，以及发生并发冲突时使用锁保护数据的成本要低于回滚事务的成本的环境中。

    悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会；另外，在只读型事务处理中由于不会产生冲突，也没必要使用锁，这样做只能增加系统负载；还有会降低了并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数据。
~~~


#### **2. varchar与char的区别是什么？大小限制？utf8字符集下varchar最多能存多少个字符**

1. 主要区别：

~~~
    (1).char是一种长度固定的类型, varchar 长度可变；
    (2).char列检索出来的值，尾部空格会被删除，varchar会被保留；
~~~

2. 大小限制：
    - char(M), 0<=M<=255, 默认为1；
    - varchar(M) 1<=M<=65535, varchar列通茶需要1或者2个额外的字节记录字符串的长度，当列长度小于255，使用一个字节记录，否则两个；适合场景：
        - a.字符串的最大长度比平均长度大很多;
        - b.列更新很少;
        - c.使用了像utf-8这样复杂的字符集(每个字符都使用不同的字节数进行存储）；

3. 存多少
    - 声明为char的列长度是固定的,char的长度可选范围在0-255之间.也就是char最大能存储`255个字符`.如果该列是utf8编码,则该列所占用的字节数=字符数*3.如果是gbk编码则该列所占用的字节数=字符数*2

    - 采用varchar类型存储数据需要1-2个字节(长度超过255时需要2个字节)来存储字符串的实际长度.如果该列的编码为gbk,每个字符最多占用2个字节,最大长度不能超过32766个字符.如果该列的编码为utf8,每个字符最多占3个字节,最大字符长度为21845（21844）.

#### **3. 如果查询很慢，你会想到的第⼀个⽅式是什么？**
- 先加explain查看, type列, Extra列
- sql语句有没有什么问题, 以下为sql语句可能存在的问题:
`高性能mysql P196`
1. 方式：

    (1). 是否向数据库请求了不需要的数据
    - 查询不需要的记录
    - 多表关联时返回全部的列
    - 总是取出全部的列
    - 重复查询相同的数据

    (2). MySQL是否在扫描额外的记录
    - 最简单的衡量查询开销的的三个指标：
        - 响应时间： 服务时间(查询真正所花时间）和排队时间（等待某些资源而没有真正执行查询的时间--可能是等IO操作完成，也可能是等待行锁）, 响应时间手很多方面的影响，比如存取引擎的锁，高并发资源竞争，硬件响应等, 用 快速上限估计法来估计查询的响应时间；
            - 快速上限估计法：了解这个查询需要哪些索引以及他的执行计划是什么，然后计算大概需要多少个顺序和随机IO，再用其乘以具体硬件条件下一次IO的消耗时间，最后累加, 就可以获得一个大概的参考值；
        - 扫描的行数和访问类型：
            - explain语句中的type列反应了访问类型，访问类型有很多种, 从全表扫描到索引扫描、范围扫描、唯一索引扫描、常数引用等；这些列出来的， 速度按从慢到快, 扫描的行数也是按从大到小；
            - explain的Extra，using where时, 一般MySQL能够使用如下三种方式应用where条件， 从好到坏依次是：
                - 在索引中使用where条件来过滤不匹配的记录， 这是在存储引擎层完成的；
                - 使用索引覆盖扫描（在Extra列中出现了Using index）来返回记录。直接从索引中过滤不需要的记录并返回命中的结果，这是在MySQL服务器层中完成的， 但无需再回表查询记录
                - 从数据表中返回数据，然后过滤不满足条件的记录（在Extra列中出现Using Where）， 这是在MySQL服务器层完成， MySQL需要先从数据表读出记录然后过滤；


        - 扫描的行数和返回的行数：理想的是两者==

#### **4.索引有什么用，大致原理是什么？索引的优点，代价（缺点）？**
`1.索引有什么用`

- 加速查询

`2. 索引的原理`

- 一种高效的数据结构， 通常使用BTree实现， 还有哈希索引，全文索引等其他索引

`3.索引的优点`

- 大大减少服务器需要扫描的数据量
- 索引可以帮助服务器避免排序和临时表
- 索引可以将随机IO变成顺序IO(1，顺序IO不需要多次磁盘寻道，2不需额外的排序操作)

`4。索引的代价`

- 加快检索， 但是降低了索引列的插入， 删除和更新值的速度， 对于写操作较多的表来说， 在索引更新方面的开销会非常大；

- 索引占据更大的空间；
    a. MYISAM 表，对于大量的索引， 有可能导致索引文件比数据文件更快的到达其limit；
    b. Innodb系统表空间里的所有InnoDB表， 都共享同一个存储空间池（数据和索引集中存储在同一个文件）， 添加索引会使表空间里用于存储的空间减少的更快， 加速到达文件的limit；

`总结`

- 编写查询语句时，应该尽可能选择合适的索引以避免单行查找、尽可能使用原生顺序从而避免额外的排序操作， 并尽可能的使用索引覆盖查询

#### **5. 外键有什么用，是否该用外键？外键一定需要索引吗？**

- 技术内幕2.13

>1. 有什么用
~~~
    1. 利用外键关系，可以在一个表里声明‘与另一个表里的某个列相关联的‘列

    2. A foreign key is a constraint, a relationship between two tables - that has nothing to do with an index 
~~~

>2. 是否该用外键
~~~
    1. 互联网行业应用不推荐使用外键： 用户量大，并发度高，为此数据库服务器很容易成为性能瓶颈，尤其受IO能力限制，且不能轻易地水平扩展；若是把数据一致性的控制放到事务中，也即让应用服务器承担此部分的压力，而引用服务器一般都是可以做到轻松地水平的伸缩；

    2.传统行业
        1>.软件应用的人数有限，换句话说是可控的；
        2>.数据库服务器的数据量也一般不会超大，且活跃数据有限；

    综合上述2句话描述，也即数据库服务器的性能不是问题，所以不用过多考虑性能的问题；另外，使用外键可以降低开发成本，借助数据库产品自身的触发器可以实现表与关联表之间的数据一致性和更新；最后一点，使用外键的方式，还可以做到开发人员和数据库设计人员的分工，可以为程序员承担更多的工作量；

    为何说外键有性能问题：
    1.数据库需要维护外键的内部管理；
    2.外键等于把数据的一致性事务实现，全部交给数据库服务器完成；
    3.有了外键，当做一些涉及外键字段的增，删，更新操作之后，需要触发相关操作去检查，而不得不消耗资源；
    4.外键还会因为需要请求对其他表内部加锁而容易出现死锁情况；
~~~

`3. 外键要索引吗？`

- 虽然不会自动创建， 还是建议安装上索引， 便于查找


#### **6. 了解Join吗，有几种**

`技术内幕P97`

- 内连接和外连接

~~~
    - 内连接只会显示在两个表里都匹配上的行；
    - 外连接还可以把其中一个表在另一个表里没有匹配的行也显示出来， 以NULL显示；
~~~

#### **7. 索引有几类， BTree与Hash索引的区别**

`高性能MySQL5.1.1`

- B-Tree，Hash， 空间索引（R-Tree），全文索引，其他索引

#### **8. innodb的两阶段锁定协议是什么情况？**
`DDIA 第七章事务两阶段锁定`
`https://en.wikipedia.org/wiki/Two-phase_locking`

- 在数据库系统领域，并发控制机制主要有两种，即锁和多版本机制。

- 两阶段锁
~~~
    1. 是一种所谓的悲观并发控制机制(pessimistic):它是基于这样的原则:如果有事情可能出错(如另一个事务所持有的锁所表示的),最好等到情况安全后再做任何事情。这就像互斥,用于保护多线程编程中的数据结构;

    2. 只要没有写入, 就允许多个事务同时读取同一个对象, 但对象只要有写入, 就需要独占访问的权限:
        a. 如果事务A读取了一个对象, 如果事务B想要写入该对象, 那么B必须要等到A提交或者是中止时才能继续;
        b. 如果事务A写入一个对象, 并且事务B想要对取, 则B必须等到A提交或者是中止才能继续;
~~~



#### **9. 数据库隔离级别，每个级别会引发什么问题，mysql默认是哪个级别**
#### **10. 数据库的隔离级别，一定会产生幻读吗？怎么解决**
- 9,10 为同一题,

`DDIA 第七章事务, 全章总结 -- 记住每个阶段对应的例子即可`
- 事务(参考第20题)

- 四种隔离级别(参考第49题)


#### **11. mysql in，not in,like, or走不走索引**
`高性能MySQL P173`
- like看情况, 如果不是通配符开头, 最左前缀原则, 是可以的, 通配符开头则不允许;
- 查询语句中使用or关键字时，只有or前后两个条件的列都是索引时，查询时才使用索引;
- 避免使用!=或＜＞、IS NULL或IS NOT NULL、IN ，NOT IN等这样的操作符,因为这会使系统无法使用索引,而只能直接搜索表中的数据;
-  能够用BETWEEN的就不要用IN,因为IN会使系统无法使用索引,而只能直接搜索表中的数据;

#### **12. 索引的分类（主键索引、唯一索引），最左前缀原则，哪些情况索引会失效**
`高性能mysql`
- 参考35题

#### **13. 数据库有哪些锁，select时怎么加排它锁**

- for update?? --完全争取
- 其他没有获取排它锁的线程, 如果要访问排它锁正在访问的对象, 会阻塞;

#### **14. 复合索引的结构**

`https://www.zhihu.com/question/36996520`

- mysql创建复合索引的规则是首先会对复合索引的最左边的，也就是第一个name字段的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个的cid字段进行排序。其实就相当于 `实现了类似order by name cid`这样一种排序规则， 所以：第一个name字段是绝对有序的，而第二字段就是无序的了。

- 那么什么时候才能用到呢?当然是cid字段的索引数据也是有序的情况下才能使用咯，什么时候才是有序的呢？观察可知，当然是在name字段是等值匹配的情况下，cid才是有序的。发现没有，观察两个name名字为 c 的cid字段是不是有序的呢。从上往下分别是4  5。这也就是mysql索引规则中要求复合索引要想使用第二个索引，必须先使用第一个索引的原因。

#### **15. 如果建了⼀个包含多个列的索引，查询的时候只⽤了第⼀列，能不能⽤上这个索引？查三列呢？MySQL为什么使用B+树作为索引？如果where条件后⾯带有⼀个 i + 5 < 100 会使⽤到这个索引吗？**
`高性能mysql`
- 很简单

#### **16. 怎么看是否⽤到了某个索引？**
- explain语句, 参见33题

#### **17. like %aaa%会使⽤索引吗? like aaa%呢? **

`技术内幕P208`

- %aaa%不会， aaa%会

#### **18. drop、truncate、delete的区别？**
-
-
-

#### **19. 你们数据库是否⽀持emoji表情，如果不⽀持，如何操作?**
- 们的数据库里面使用的是utf8编码，普通的字符串或者表情都是占位3个字节，所以utf8足够用了，但是移动端的表情符号占位是4个字节，普通的utf8就不够用了，为了应对无线互联网的机遇和挑战、避免 emoji 表情符号带来的问题、涉及无线相关的 MySQL 数据库建议都提前采用utf8mb4 字符集;

- UTF- 8：Unicode Transformation Format-8bit，允许含BOM，但通常不含BOM。是用以解决国际上字符的一种多字节编码，它对英文使用8位（即一个字节），中文使用24为（三个字节）来编码。UTF-8包含全世界所有国家需要用到的字符，是国际编码，通用性强;

- UTF8MB4：MySQL在5.5.3之后增加了utf8mb4的编码，mb4就是most bytes 4的意思，专门用来兼容四字节的unicode

#### **20. 数据库中事物的特征？**（ACID）
`DDIA 第七章`

- 事务就是一组原子性的sql查询，或者说是一个独立的单元；

- start transaction 开始一个事务，事务中的所有读写操作被视为单个操作来执行, 要么使用commit，要么使用Rollback撤销；
~~~
    - A 原子性：一个事务必须被视为一个不可分割的最小单位，要么全部执行，要么全部不执行；

    - C 一致性：数据库总是从一个一致性的状态转换到另一个一致性的状态（两个账户之间的balance不会失衡）；

    - I 隔离性：同时执行的事务是相互隔离的，一个事务在提交前，对其他事务是不可见的；

    - D 持久性：一旦事务提交，则其所做的修改会永久的保存在数据库中；
~~~


#### **21. mysql的引擎,区别与适用场景。Innodb 和 MyISAM 的区别**
`技术内幕P76`
- 区别
~~~
    1. 索引相关:
        a. MyISAM使用前缀压缩技术使用索引更小, InnoDB则按照原数据格式进行存储;
        b. MyISAM索引通过数据的物理位置引用被索引的行, 而InnoDB则根据主键引用;
~~~
- 优劣

- 使用场景

#### **22. primary key 和 unique key 的区别**

`技术内幕P86`

- 每个表只包含一个primary key， 可以有多个unique key；

- pk 不能包含NULL值，unique行，（NULL值不与任何值相等，甚至是另一个NULL值）

#### **23. 为何，以及如何分区、分表；**
`http://blog.51yip.com/mysql/1029.html` -- mysql分表，分区的区别和联系

`http://blog.51yip.com/mysql/949.html`
>1 为何分表
~~~
    1. 当一张表的数据很大时， 查询耗时，分表的目的就在于减小数据库负担，缩短查询时间；
    2. mysql执行机制有行锁（Innodb），表锁（MyIsam），数据大之后的表锁不切实际；
~~~
>2.如何分表
~~~
    1.根据实际业务情况分，预先估计会出现大数据量并且访问频繁的表，将其分为若干个表：
        这种预估大差不差的，论坛里面发表帖子的表，时间长了这张表肯定很大，几十万，几百万都有可能。 聊天室里面信息表，几十个人在一起一聊一个晚上，时间长了，这张表的数据肯定很大。像这样的情况很多。所以这种能预估出来的大数据量表，我们就事先分出个N个表，这个N是多少，根据实际情况而定。以聊天信息表为例：

        我事先建100个这样的表，message_00,message_01,message_02..........message_98,message_99.然后根据用户的ID来判断这个用户的聊天信息放到哪张表里面，你可以用hash的方式来获得，可以用求余的方式来获得，方法很多，各人想各人的吧；


    2.利用merge存储引擎来实现分表
~~~



#### **24. NoSQL了解么，和关系数据库的区别**
`技术内幕2.6.2.5`
`InnoDB引擎4.9`
~~~
    非关系型数据库的优势：
    1. 性能NOSQL是基于键值对的，而且不需要经过SQL层的解析，所以性能非常高。
    2. 可扩展性同样也是因为基于键值对，数据之间没有耦合性，所以非常容易水平扩展。

    关系型数据库的优势：
    1. 复杂查询可以用SQL语句方便的在一个表以及多个表之间做非常复杂的数据查询。
    2. 事务支持使得对于安全性能很高的数据访问要求得以实现。
~~~

#### **25. 存储过程的优点**

（1）.存储过程只在创造时进行编译，以后每次执行存储过程都不需再重新编译，而一般 SQL 语句每执行一次就编译一次,所以使用存储过程可提高数据库执行速度。 

（2）.当对数据库进行复杂操作时(如对多个表进行 Update,Insert,Query,Delete 时），可将此复杂操作用存储过程封装起来与数据库提供的事务处理结合一起使用。这些操作，如果用程序来完成，就变成了一条条的 SQL 语句，可能要多次连接数据库。而换成存储，只需要连接一次数据库就可以了。 

（3）.存储过程可以重复使用,可减少数据库开发人员的工作量。 

（4）.安全性高,可设定只有某此用户才具有对指定存储过程的使用权。

#### **26. 如何实现数据库的原子性，可以用伪代码实现吗**
- to be continued

#### **27. 如果有很多数据插⼊MYSQL 你会选择什么⽅式?（一个数据库，每十分钟会接收到百万级的数据进行插入，应该怎么设计？）**


#### **28. 在极端情况下，系统缓存全部失效，该如何防止流量全部打到数据库上**
`缓存重建问题`
`相关问题--redis开发与运维都有涉及`
-面对cache aside可能出现的全部打在数据库的情况， 比较简单的方式就是预热，可以用脚本来提前写入到 cache 热缓存。或者改用缓存策略， 使用Write-Through 直接写缓存，然后更新到数据库。

- 这个问题可以用一些可以提供持久化功能的缓存来实现，比如Redis，在未开启aof的情况下，其定期dump出来的rdb文件出能自动恢复出绝大部分数据；

- 而MongoDB与上面的方式不太一样，MongoDB采用mmap来将数据文件映射到内存中，所以当MongoDB重启时，这些映射的内存并不会清掉，因为它们是由操作系统维护的（所以当操作系统重启时，MongoDB才会有相同问题）。相对于其它一些自己维护Cache的数据库，MongoDB在重启后并不需要进行缓存重建与预热；

- 另外，新浪微博的timyang也曾经提出过一种缓存重建加锁的方式，也能部分解决此问题。简单来说就是缓存重建时，当多个客户端对同一个缓存数据发起请求时，会在客户端采用加锁等待的方式，对同一个Cache的重建需要获取到相应的锁才行，只有一个客户端能拿到锁，并且只有拿到锁的客户端才能访问数据库重建缓存，其它的客户端都需要等待这个拿到锁的客户端重建好缓存后直接读缓存，其结果是对同一个缓存数据，只进行一次数据库重建访问。但是如果访问分散比较严重，还是会瞬间对数据库造成非常大的压力。

#### **29. 数据库三范式**

`https://www.zhihu.com/question/24696366`

#### **30. 聚簇索引**
- 定义:
~~~
    1. 主键索引, 既存储索引值, 又在叶子中存储行的数据;
    2. 没有主键, 会选择unique key 做主键;
    3. 如果没有unique key, 则会在内部生成一个rowid做主键;

    二级索引的叶子节点保存的不是指向行的物理位置的指针,而是行的主键值;
~~~

- 优势:
~~~
    1. 根据主键找, 效率高;
    2. 
~~~

- 劣势:
~~~
    0.最大限度的提高了IO密集型应用的性能, 但如果数据在内存中, 访问的顺序就不重要了,
    1.如果碰到主键不规则的数据插入, 容易造成频繁的页分裂(随之相伴的是大量的数据碎片);
    2.二级索引的访问需要两次索引的查找;
~~~

- 启发:
~~~
    使用InnoDB时,应该尽可能地按主键顺序插入数据;
~~~

#### **31. 对于最左前缀不易区分的列, 比如url的存储与查找， 如何处置?**
- 把内容倒过来插入, 然后建立索引 -- `高性能Mysql P157页也有涉及`
- 伪哈希索引 (crc(32))--`高性能Mysql P148的实例非常值的一看`


#### **32. sql语句优化**
~~~ 
    1. sql语句的时间花在哪?
        - 等待时间, 执行时间,
    2. 执行时间, 花在哪?
        - 查找
        - 取出
    3. 如何查的快
        - 查的快, 尽量走索引
        - 取的快, 索引覆盖
        - 传输少, 更少的行和列
~~~

#### **33. explain语句**
`高性能mysql 附录A`
- 字段解释:
~~~
    1. id: 查询的序号; 
    2. select_type:
        a. SIMPLE 简单查询(不包含子查询);
        b. PRIMARY 含子查询或者派生查询;
            (1) subquery: 非From 子查询;
            (2) derived: from子查询;
            (3) union
            (4) union result: 
    3. table:
        a. 实际的表名;
        b. 表的别名;
        c. derived: from 子查询时;
        d. null: 直接计算结果, 不走表;

    4. type: 查询的方式;
        a. all:全表扫描;
        b. index: All扫描所有的数据行, 而index扫描所有的索引节点;
        c. range: 能根据索引做范围扫描;
        d. ref: 通过索引可以直接引用到某些数据行;
        e. const, system, null: 最优， 优化到常量级别；

    5. possible keys: 可能用到的键;
        a. 可能用到的索引, 最终只会用一个;

    6. key: 真正用到的索引;

    7. key_len: 最终用到的索引的长度;

    8. ref: 两表联查, 是否有引用关系;

    9. rows: 估计本次将要查询的行数;

    10. Extra: 额外的信息;
        a. index: 索引覆盖
        b. using where: 光靠索引定位不了， 还得where 来判断下；
        c. using temporary： 产生了临时表；
        d. using filesort： 文件排序(通常再内存， 如果取出的列是text类型， filesort将发生在磁盘上）；

~~~
#### **34. 缓存更新 策略**
`https://coolshell.cn/articles/17416.html`

- 一. Cache Aside
~~~
    1. 最最常用的pattern, 逻辑如下:
        失效: 应用程序先从Cache取数据, 没有取到, 则从数据库取, 成功后, 放入缓存;
        命中: 应用程序直接从Cache获取数据, 返回;
        更新: 先把数据存到数据库中, 成功后, 再让缓存失效;
~~~

-二. Read through  -- 细节不完善
~~~
    1. 在查询中更新缓存, 当缓存失效时, Cache aside是由调用方更新缓存, 而read through则用缓存服务自己来加载;
~~~

-三. Write through -- 细节不完善
~~~
    1. 逻辑如下:
        命中: 直接获取数据;
        失效: 从数据库读取数据进缓存, 然后从缓存返回数据给调用者;
        更新:
            a. 如果没有命中缓存, 则直接更新数据库, 然后返回;
            b. 如果命中了缓存, 则更新缓存, 然后由Cache自己更新数据库(这是一个同步操作);
~~~

-四. Write behind caching
~~~
    1. Write Behind 又叫 Write Back, 在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。
    2. 一些了解Linux操作系统内核的同学对write back应该非常熟悉，这不就是Linux文件系统的Page Cache的算法吗?
~~~

#### **35. btree 索引**
`高性能Mysql5.1.1`
- BTree索引简介:
~~~
    1. BTree 索引意味着所有的值是按顺序存储的（很适合范围查找）， 并且每个叶子节点到根节点的距离相同；

    2. BTree 适用于全键值，键值范围, 键的最前缀查找, 精确匹配某一列并范围匹配另一列；
~~~

- BTree索引限制：
~~~
    1. 如果不是按照索引的最左列开始查找，则无法使用索引；

    2. 不能跳过中间的索引；

    3. 如果中间有某个列的范围查询，则右边所有的列都无法使用索引； 
~~~

#### **36. 哈希 索引**
`高性能Mysql5.1.1`
- 哈希索引简介:
~~~
    1. 基于哈希表实现,查询数据很快，只有精确匹配索引所有列的查询，才有效；

    2. 对每一行数据， 存储引擎都会对被索引的列计算一个哈希码， 哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存每个指向数据行的指针;

    3. 只有Memory索引支持哈希索引
~~~

- 哈希索引限制：
~~~
    1. 哈希索引只包含哈希值和行指针， 没有索引覆盖一说；

    2. 索引的数据并不是根据索引（数据）值顺序存储的， 所以无法用于排序；

    3. 不支持部分匹配列查找； 

    4. 哈希冲突多， 查询费事， 维护代价高；
~~~

#### **37. InnoDB的自适应哈希索引**
- InnoDB
~~~
高性能Mysql P148

    当InnoDB注意到某些索引值被使用的非常频繁时，他会在内存中基于B-Tree索引之上再创建一个哈希索引，这是引擎自动和内部的行为，用户无法控制和配置；
~~~

#### **38. 设计索引有什么注意点**
- 注意要点
~~~
    1. 为用于搜索，排序或分组的列创建索引，也就是说，最佳索引列是那些出现在where 子句，连接子句，或者是出现在order by或 GROUP BY子句中的列；

    2. 认真考虑数据列的基数，列的基数是指它所容纳的所有非重复值的个数，通常来说，列的基数越高（包含的唯一值多， 重复值少）索引的效果越好；

    3. 索引值短小，对于InnoDB更有好处，主键值会在每一个二级索引（把主键值和二级索引值存储在一起）中重复出现，因此，如果主键值越长，则会导致每一个二级索引越大；

    4. 索引字符串的前缀, 想要对字符串列进行索引, 应当尽量指定前缀长度；

    5. 利用最左前缀，当创建包含n个列的复合索引时，实际上会创建n个专供MySQL使用的索引，复合索引修当于多个索引， 因为索引中最左边的任意数据列集合都可以用于匹配(参考14题， 复合索引结构)

    6. 不要建立过多的索引：1.每增加一个索引, 需要额外的磁盘空间，2.更新操作,需相应的更新索引（P205）,3索引太多时，将无法使用最好的索引（增加查询优化的工作）

    7. 让参与比较的索引类型保持匹配 ：散列索引不适合做范围查找

    8. 尽可能使用索引覆盖查询；
~~~

#### **39. 高性能的索引策略**
`高性能MySQL 5.3`
>1. 独立的列： 索引列不能使表达式的一部分， 也不能是函数的参数；
>2. 前缀索引和索引选择性：
~~~
    a. 完整列的选择性： COUNT(DISTINCT city)/COUNT(*)， 不同值/总数
    b. 选择性要足够高，达到上述完整列的选择性即可（即前缀不能太长）；
    
    如何创建前缀索引：
    ALTER TABLE sakila.city_demo ADD KEY(city(7))
~~~
>3. 多列索引：
~~~
    a.此处主要讲了Mysql5.0之后引入了一种x新的策略--索引合并;
    b.索引合并有时候是一种优化的结果, 但实际上更多的时候说明了表上的索引建的很糟糕;
    c.如果再explain中看到有索引合并(extra列), 检查查询和表的结构;
~~~
>4. 选择合适的索引列顺序:
~~~
    a. 在一个多列B-Tree索引中, 索引列的顺序意味着索引首先按照最左列进行排序;
    b. 如何选择索引的顺序, 经验法则:
        (1). 当不需要考虑排序或者分组的时候: 将选择性最高的列放在索引的最前列(实际业务中, 需要根据查询频率做相应的调整)

~~~
>5. 聚簇索引
~~~
    - 参考题30
~~~
>6. 覆盖索引 
~~~
    - 参考题41
~~~
>7. 使用索引扫描来做排序
~~~
    - 参考题 46
~~~
>8. 压缩(前缀)索引
>9. 冗余和重复索引
>10. 未使用的索引
>11. 索引和锁

#### **40. Union的规则**
~~~
“Mysql技术内幕P107”
    1. 列名和数据类型：
        a. 列名以第一个select语句为准；
        b. 通常对应列数据类型应该相同，如果不同，MySQL会进行必要的类型转换；
    2. 重复行处理： 
        a. 默认情况下会自动去掉重复的行;
        b. 如果要保留重复的行, 改 union 为 union all;
    3. 如果要使用 order by 和 limit:
        a. union 需要使用order by, 需要将 select 语句括起来, order by的列字段, 以第一个select语句中的列字段为准;
        b. limit 照常使用就好;
~~~

#### **41. 索引覆盖**
- 定义:
~~~
    如果一个索引包含所需要查询的字段的值, 就称之为覆盖索引;

    覆盖索引必须要存储索引列的值,只有BTree索引支持;
~~~
- 优势
~~~
    1. 索引条目小, 缓存负载小, 数据量大, 可能大部分时间都花在数据拷贝上了;
    2. MyISAM在内存中只缓存索引, 数据则依赖操作系统来缓存, 因此访问数据需要一次系统调用;
    3. 对InnoDB尤其有效, 可减少对主键索引的二次查询;
~~~


#### **42 . 查询性能优化**
`高性能Mysql--第六章`

#### **43. 为何，以及如何分区**
`http://blog.51yip.com/mysql/1013.html`
`DDIA -- 第六章`
- 对于非常大的数据集,或非常高的吞吐量,仅仅进行复制是不够的:我们需要将数据进行分区(partitions),也称为分片(sharding);

- 一、键值数据的分区:
~~~
    a. 分区目标是将数据和查询负载均匀分布在各个节点上;
    b. 如果分区是不公平的;避免热点(不均衡导致的高负载的分区)最简单的方法是将记录随机分配给节点;此策略的缺点:当你试图读取一个特定的值时,你无法知道它在哪个节点上,所以你必须并行地查询所有的节点。
~~~
>1. 根据键的范围分区
~~~
    a. 为了均匀分配数据,分区边界需要依据数据调整,分区边界可以由管理员手动选择,也可以由数据库自动选择;
    b. 在每个分区中,我们可以按照一定的顺序保存键; 好处是进行范围扫描非常简单, 缺点是某些特定的访问模式会导致热点;
~~~

>2. 根据键的散列分区
~~~
    a. 许多分布式数据存储使用散列函数来确定给定键的分区;一旦你有一个合适的键散列函数,你可以为每个分区分配一个散列范围;
    b. 出于分区的目的,散列函数不需要多么强壮的加密算法:例如,Cassandra和MongoDB使用MD5;
    c. 分区边界可以是均匀间隔的,也可以是伪随机选择的(在这种情况下,该技术有时也被称为一致性哈希);
    
    缺点:
        失去了键范围分区的一个很好的属性:高效执行范围查询的能力;在MongoDB中,如果您使用了基于散列的分区模式,则任何范围查询都必须发送到所有分区;

    策略(DDIA P179):
        组合索引方法
        Cassandra中的表可以使用由多个列组成的复合主键来声明。键中只有第一列会作为散列的依据,而其他列则被用作Casssandra的SSTables中排序数据的连接索引;
        场景: 社交媒体, 一个用户可能发布多更新;如果更新的主键选择为(user_id, update_timestamp),那就可以有效的检索特定用户某个时间间隔内按时间戳排序的所有更新;
~~~

>3. 负载倾斜与消除热点
~~~
    场景:某个人名人发布一条状态, 这个事件可能导致大量写入同一个键;
    策略:
        在主键的开始或者是结尾添加一个随机数(一个两位数的十进制随机数就可以将主键分散为100钟不同的主键,从而存储在不同的分区中);
    缺点:
        任何读取都必须要做额外的工作,因为他们必须从所有100个主键分布中读取数据并将其合并。此技术还需要额外的记录,需要一些方法来跟踪哪些键需要被分割。
~~~

>4. 分片和次级索引
- 如果涉及次级索引, 情况将更加复杂;
~~~

~~~

#### **44. InnoDB 和MyISAM的数据分布对比**
- MyISAM 按照数据插入的顺序存储在磁盘上, 主键索引和其他索引没有什么不同, 主键索引就是一个名为primary的唯一非空索引;

- InnoDB聚簇索引的每一个叶子节点都包含了主键值,事务ID, 用于事务和MVCC的回滚指针,以及剩余的列;

#### **45. 延迟关联**
`高性能mysql P173`

#### **46. 使用索引扫描做排序**
- 如果 explain 出来的type 列为 index, 说明mysql使用了索引扫描来做排序;
- 限制条件:
~~~
    1. 索引列的顺序和order by 子句的顺序完全一致;
    2. 如果需要关联多张表, 只有当ORDER BY子句引用的字段全部为第一个表时;
    3. 需要满足最左前缀的要求(有特例, P176);
~~~

#### **47. 查询性能优化**
- 一.  慢查询基础: 优化数据访问
>1. 是否向数据库请求了不需要的数据;
~~~
    a. 
        (1). 查询不需要的记录, select大量数据, 然后取少部分, 简单有效的办法, 查询后面加limit
        (2). 多表关联时返回全部的列;
        (3). 总是取出全部的列;
        (4). 查询重复相同的数据;
~~~

>2. mysql 是否扫描额外的记录
~~~
    一般mysql能够使用如下三种方式应用where条件, 从好到坏依次为:
    1. 在索引中使用where条件来过滤不匹配的记录,这是在存储引擎层完成的;
    2. 使用索引覆盖扫描(Extra Using index)来返回记录, 服务器层完成, 无需回表查询;
    3. 从数据表返回数据, 然后过滤,这是再服务器层完成的;
~~~

- 二. 重构查询的方式;
>1. 一个复杂查询还是多个简单查询;
>2. 切分查询--以删除为例, 一次大的删除更好的方式是分批次删;
>3. 分解关联查询;
~~~
    1. 缓存效率更高;
    2. 查询分解后, 执行单个查询可以减少锁的竞争;
    高性能P203
~~~


- 三. 查询执行的基础: 但我们向mysql发送一个请求时,mysql到底做了些什么?
~~~
    1.客户端发送一条查询给服务器;
    2.服务器先检查缓存, 如果命中了缓存, 则立刻返回结果;
    3.服务器进行SQL解析, 预处理, 再由优化器生成对应的执行计划;
    4.根据优化器生成的执行计划, 调用存储引擎的API来执行查询;
    5.将结果返回给客户端;
~~~
>1. mysql 客户端/服务器通信协议
~~~
    协议半双工：客户端与服务器之间的通信协议是半双工，要么服务器给客户端发信息， 要么客户端给服务器发，不能同时发生；
    缺点：
        一旦一端开始发送消息，另一端要接收完整个消息才能响应它；
    对于一个mysql连接(线程), 任何时刻都有一个状态, 最简单的就是 show full processlist, 状态列表: 高性能P207
~~~
>2. 查询缓存

>3. 查询优化处理 **--重点**
~~~
    1. 首先是sql的解析, 接着预处理器验证权限;
    2  优化器将语法树转化为执行计划;一条查询可能有很多种执行方式, 优化器的作用就是找到最好的那条;
    3. mysql使用基于成本的优化器;
    4. 有很多原因可能导致优化器选择错误的执行计划 -- 示例: 高性能mysql P209
    5. mysql能够处理的优化类型: --示例: 高性能mysql P211
        a.列表In()的比较:mysql中IN列表的数据会先进行排序, 然后通过二分查找的方式确定列表中的值是否满足, 这是一个O(log n)复杂度的操作, 等价的转换成OR查询的复杂度为O(n), In()列表中有大量值时, mysql的处理速度会更快;
    6.执行计划
        a. mysql生成一棵指令查询树, 存储引擎执行完成这棵树,并返回结果;
    7. 关联查询优化器:
        a. 通常优化器定义的关联顺序比人自己关联的要准确
    8. 排序优化(同城filesort)
        a. 数量小于"排序缓冲区", mysql使用内存进行"快速排序";
        b. 内存不够, 先将数据分块, 对每个块使用"快速排序",最后merge

~~~
>4. 查询执行引擎

>5. 返回结果给客户端

- 四. 查询优化器的局限性
>1. 关联子查询
>2. UNION 的限制
>3. 索引合并优化
>4. 等值传递
>5. 并行执行
>6. 哈希关联
>7. 松散索引扫描
>8. 最大值和最小值优化
>9. 在同一个表上查询和更新

- 五. 查询优化器的提示

- 六. 优化特定类型的查询 **--重点**
>1. 优化COUNT()查询;
>2. 优化关联查询;
>3. 优化子查询;
>4. 优化group by 和 distinct 查询;
>5. 优化LIMIT分页;
>6. 优化SQL_CALC_FOUND_ROWS;
>7. 优化UNION查询
>8. 静态查询分析
>9. 使用用户自定义变量

#### **48. schema与数据类型优化**
- 一. 选择优化的数据类型
~~~
    1. 几个简单的原则:
        a. 更小的通常更好;
        b. 简单就好;
        c. 尽量避免NULL
~~~
>1. 整形类型
~~~
    1. tinyint, smallint, mediumint,  int, bigint 分别对应:
             8,       16,        24,   32,     64   位存储空间;

    2. 可以指定宽度, 如INT(11); -- 一些mysql客户端的设置, 用来显示字符的个数;
~~~

>2. 实数类型 
~~~
    - to be finished
~~~

>3. 字符串类型 
~~~
    1. varchar:
        a. 需要额外1个(列长度255以内)或者2个字节记录字符串的长度;
    2. varchar适用场景:
        a. 字符串的最大长度比平均长度大很多;
        b. 列的更新很少;
        c. 字符集使用了utf-8等类似的复杂字符集;

    3. char:
        a. 定长;
        b. 末尾空格会被删掉;
    4. char适用场景:
        a. 短, 而且列值长度相近的字符串, 例如md5;
        b. 经常变更的;

    5. BLOB 和 TEXT:
        a. mysql 把每个BLOB和TEXT值当作一个独立的对象处理, 都是为存储很大的数据而设计的字符串数据类型;
        b. BLOB和TEXT之间仅有的不同是, BLOB存储的是二进制数据, 没有排序规则和字符集, 而TEXT有;
    
    6. 枚举：
        a．非常紧凑，通常会将列值压缩到一个或者两个字节中, 实际存储的是整数；
        b. 在.frm 文件中保存"数字 - 字符串"映射关系的"查找表", 同理排序也是按照整数来排的;
    7. 枚举缺点:
        a. 列值是固定的, 添加, 删除字符串必须使用ALTER TABLE;

~~~

>4. 日期和时间类型 
~~~
    1. datetime
        a.范围1001~9999, 精度为秒;
        b. 8字节存储;
        c. 标准格式: "1991-01-17 18:18:18"

    2. timestamp
        a. 1970.01.01以来的秒数, 范围1970~2038;
        b. 4字节存储;
        c. 显示的值依赖时区;

    3 建议:
        a. 尽量使用timestamp, 更节省空间;
        b. 存储比秒更小粒度的时间和日期: 使用bigint 存储微秒级别的时间戳或者是double 存储秒之后的小数部分;
~~~

>5. 位数据类型 
~~~
    - to be finished
~~~

>6. 选择标识符
~~~
    - to be finished
~~~

>7. 特殊类型数据
~~~
    - to be finished
~~~

- 二. MySQL schema设计中的陷阱
~~~
    1. 太多的列:
        Mysql 的存储引擎API工作时需要在"服务层"和"存储引擎层"之间通过行缓冲格式拷贝数据, 然后在服务器层将缓冲内容解码成各个列;
    2. 太多的关联
    3. 全能的枚举
    4. 变相的枚举
    5. 不必要的NULL
~~~

- 三. 范式和反范式
`参见题29`
>1. 范式的优缺点
>2. 反范式的优缺点
>3. 混用范式化和反范式化

- 四. 缓存表和汇总表
>1. 物化视图
>2. 计数器表

- 五. 加快ALTER TABLE操作的速度
>1. 只修改 .frm文件 
>2. 快速创建MyISAM 索引



#### **49. 四种隔离级别**
>1. read uncommitted（读未提交)
~~~
    1. 它可以防止脏写，但不防止脏读
    2. 事务中的修改, 即使没有提交, 对其他事务都是可见的, 称之为脏读;
    3. 实际中非常少用;
~~~
    
>2. read commited （提已交读）== 不可重复读 -- 参考第50题
~~~
    1. 满足隔离性的简单定义：一个事务开始时，只能看见已经提交的事务的所做的修改，也就是说，一个事务从开始到提交之前，所做的任何改变对其他的事务是不可见的， 也叫“不可重复读”， 因为两次执行同样的查询，可能得到不一样的结果；

    2. 又被称为: 
~~~
    
>3. repeatable read (可重复读) == 快照隔离 -- 参考第51题
~~~
    1. 每个事务都从数据库的一致快照(consistent snapshot)中读取——也就是说,事务可以看到事务开始时在数据库中提交的所有数据。即使这些数据随后被另一个事务更改,每个事务也只能看到该特定时间点的旧数据;

    2. 快照隔离对长时间运行的只读查询(如备份和分析)非常有用;
~~~

>4. serialization （可串行化）
    - 会在读取的每一行数据上都加锁； 最高级别，强制事务串行执行，避免了幻读的问题;


#### **50. 读已提交(不可重复读)**
~~~
    术语解释：
        脏写：如果两个事务同时尝试更新数据库中的相同对象，我们通常认为后面的写入会覆盖前面的写入。但是，如果先前的写入是尚未提交事务的一部分，又会发生什么情况，后面的写入会覆盖一个尚未提交的值？这被称作脏写
~~~

>1. 它提供了两个保证：

    （1）从数据库读时，只能看到已提交的数据（没有脏读）
        a.防脏读原因:
            - 可能只看到部分数据更新, 以邮件+未读邮件计数器为例;
            - 事务可能回滚;

    （2）从数据库写时，只会覆盖已写入的数据（没有脏写）
        a. 脏写可能存在的例子:
            - DDIA P206  

>2. 实现读已提交：

    （1）防止脏写，最常见的情况是：数据库通过使用“行锁”来防止脏写：当事务想要修改特定对象，它必须首先获得该对象的锁，然后必须持有该锁直到事务被提交或者中止，一次只有一个事务可以持有任何给定对象的锁；如果另一个事务要写入同一个对象，必须等到第一个事务提交或者是中止后，才能获得该锁并继续；

    （2）防止脏读，对于写入的每个对象，数据库都会记住旧的已提交值，和当前写入的新值，当事务在正在进行时，任何其他读取对象的事务都会拿到旧值；

>3. 读已提交时可能发生的问题:
~~~
    (1). 示例 DDIA P207
    解决方法:
        快照隔离(可重复读)
~~~

#### **51. 可重复读(快照隔离)**
>1. 实现快照隔离:
~~~
    (1). 与读已提交类似, 快照隔离使用写锁来防止脏写;
    (2). 关键原则: 读不阻塞写, 写不阻塞读;
    (3). 为实现快照隔离, 数据库保留着一个对象的几个不同的提交版本, 这种技术被称为多版本并发控制(MVCC); 
    (4). 支持快照隔离的存储引擎通常也使用MVCC实现读已提交, 读已提交实际上就是保存了同一个对象的两个版本;
    (5). 具体过程:
        a. 当一个事务开始时, 它被赋予一个唯一的, 永远增长的事务ID, 每当事务向数据库写入任何内容时, 它所写入的数据都会被标记上写入者的事务ID;
        b. 一致性快照的可见性规则;
        C. 索引和快照隔离;
        d. 可重复读与命名混淆;
~~~

>2. 丢失更新
- 解决方案
~~~
    1. 原子写： 原子操作通常通过在读取对象时，获取其上的排他锁来实现，这种技术有时也被称作游标稳定性；
    2. 显示锁定：
    3. 自动检测丢失的更新: 原子操作和锁是通过强制读取-修改-写入序列按顺序发生，来防止丢失更新的方法。另一种方法是允许它们并行执行，如果事务管理器检测到丢失更新，则中止事务并强制它们重试其读取-修改-写入序列。
    4. 比较并设置（CAS）：只有当前值从上次读取时一直没有改变，才允许更新发生，如果当前值与先前读取的值不匹配，则更新不起作用，且必须重试读取-修改-写入序列；
~~~

#### **52. 可序列化**
>1. 可序列化：
- 读已提交和快照隔离级别会阻止某些竞争条件，但不会阻止另一些, 例如, 写入偏差和幻读
    ~~~
        0. 丢失更新
            a. 对应单一对象, 比如计数器

        1. 写入偏差
            a. 对应多对象, 医生值班的例子

        2. 幻读 -- 导致写入偏差的罪魁祸首
            - 一个事务中的写入改变另一个事务的搜索查询的结果,被称为幻读
            a. 支付,体现, 余额
    ~~~
- 通常被认为是最强的隔离级别，它保证即使事务可以并行执行，最终的结果与连续挨个执行一样，也就是说数据库可以防止所有可能的竞争条件；

#### **53. mysql表的复制**
~~~
    1.表与数据的复制->>实现表结构和数据的同步

    create table desttable select * from srctable;

            (desttable:目标表，srctable：原表）



    2.表结构的复制->>只实现表结构的同步

    create table desttable select  * from srctable where 0>1;
    或者
    create table desttable LIKE srctable;


    3.全表记录的复制->>将一个表的全部记录插入另外一个表

    insert into desttable select * from srctable;



    4.部分字段的复制

    insert into desttable(字段一，字段二.......) select (字段一，字段二.......)  from srctable;
~~~

#### **54. mysql慢查询日志**

#### **55. MySQL为什么使用B+树作为索引**
`http://blog.codinglabs.org/articles/theory-of-mysql-index.html` -- 此文章非常值得一读
- B-树和B+树最重要的一个区别就是: B+树只有叶节点存放数据，其余节点用来索引，而B-树是每个索引节点都会有Data域, 这就决定了B+树更适合用来存储外部数据，也就是所谓的磁盘数据;
~~~
    1. 一般来说索引非常大，尤其是关系性数据库这种数据量大的索引能达到亿级别，所以为了减少内存的占用，索引也会被存储在磁盘上。那么Mysql如何衡量查询效率呢？磁盘IO次数，B-树（B类树）的特定就是每层节点数目非常多，层数很少，目的就是为了就少磁盘IO次数，当查询数据的时候，最好的情况就是很快找到目标索引，然后读取数据，使用B+树就能很好的完成这个目的，但是B-树的每个节点都有data域（指针），这无疑增大了节点大小，说白了增加了磁盘IO次数（磁盘IO一次读出的数据量大小是固定的，单个数据变大，每次读出的就少，IO次数增多，一次IO多耗时啊！），而B+树除了叶子节点其它节点并不存储数据，节点小，磁盘IO次数就少。这是优点之一。
    
    2. 另一个优点是什么，B+树所有的Data域在叶子节点，一般来说都会进行一个优化，就是将所有的叶子节点用指针串起来。这样遍历叶子节点就能获得全部数据，这样就能进行区间访问;
~~~

#### **56. 建立一个表，id,name,id自增长，且为主键在原来的表上增加一列，创建时间列，并获取当前系统时间找出创建时间在某个时间范围以内，并按照创建时间降序排列在原来的表上增加一百条数据，名字字段每条后边加个0，比如第一个是name,下边是name0,name00....**

#### **57. 邦计划, 写一条sql语句统计当天的销量（输出一个list，即售出物品-售出数量）**

#### **58. MySQL极限**

#### **59. MySQL慢查询开启，语句分析**
#### **60. 如何防止数据库单点问题**
#### **61. 数据库主从复制配置**
#### **62. inndob如何手动加共享锁与排他锁**
#### **63. 查询缓慢和解决方式（explain、慢查询日志、show profile等）**
#### **64. 数据库崩溃时事务的恢复机制（REDO日志和UNDO日志）**
#### **65. mysql 如何执行关联查询**
`高性能P214`
- 嵌套循环关联
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**

#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**
#### **.**